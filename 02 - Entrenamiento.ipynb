{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.img_toolbox import get_letters_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creo el dataset con imágenes y sus etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_images_folder = \"input/letter_dataset/training\"\n",
    "\n",
    "X, y = get_letters_dataset(letter_images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de features:  39768\n",
      "Numero total de labels 39768\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero total de features: \", len(X))\n",
    "print(\"Numero total de labels\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta imagen:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponde a la letra o número:  S\n"
     ]
    }
   ],
   "source": [
    "# Por ejemplo:\n",
    "print(\"Esta imagen:\")\n",
    "plt.imshow(X[1500], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(\"Corresponde a la letra o número: \", y[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1] (this improves training)\n",
    "X = np.array(X, dtype=\"float\") / 255.0\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar datos de Entrenamiento de datos de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hago one-hot encoding con las etiquetas (cada letra/número estará separado en una columna)\n",
    "lb = LabelBinarizer().fit(y_train)\n",
    "y_train = lb.transform(y_train)\n",
    "y_test = lb.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filename = \"model_labels.dat\"\n",
    "\n",
    "# Guardo los mapeos del labels de los one-hot encodings.\n",
    "# Usaré este mapa para entender la predicción que haré (justo al final del notebook `03 - Usar el modelo y probar leer captchas`)\n",
    "with open(labels_filename, \"wb\") as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense\n",
    "\n",
    "# Instancio el modelo\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añado una Primera Capa convolucional con max pooling\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añado una Segunda Capa convolucional con max pooling\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añado 500 nodos de capas ocultas intermedias\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añado la última capa: la Capa de Salida con 36 nodos (uno por cada letra/número posible en nuestro set de datos)\n",
    "num_of_possible_characters = 36\n",
    "\n",
    "model.add(Dense(num_of_possible_characters, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construyo el modelo TensorFlow\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 2.0237 - accuracy: 0.4636 - val_loss: 1.1272 - val_accuracy: 0.6955\n",
      "Epoch 2/10\n",
      "884/884 [==============================] - 55s 63ms/step - loss: 0.9896 - accuracy: 0.7371 - val_loss: 0.9541 - val_accuracy: 0.7459\n",
      "Epoch 3/10\n",
      "884/884 [==============================] - 56s 64ms/step - loss: 0.8154 - accuracy: 0.7863 - val_loss: 0.8468 - val_accuracy: 0.7709\n",
      "Epoch 4/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 0.7121 - accuracy: 0.8153 - val_loss: 0.7940 - val_accuracy: 0.7924\n",
      "Epoch 5/10\n",
      "884/884 [==============================] - 56s 64ms/step - loss: 0.6289 - accuracy: 0.8348 - val_loss: 0.7915 - val_accuracy: 0.7929\n",
      "Epoch 6/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 0.5535 - accuracy: 0.8522 - val_loss: 0.7904 - val_accuracy: 0.7928\n",
      "Epoch 7/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 0.4904 - accuracy: 0.8684 - val_loss: 0.7728 - val_accuracy: 0.8090\n",
      "Epoch 8/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 0.4276 - accuracy: 0.8828 - val_loss: 0.7790 - val_accuracy: 0.8088\n",
      "Epoch 9/10\n",
      "884/884 [==============================] - 57s 64ms/step - loss: 0.3680 - accuracy: 0.8975 - val_loss: 0.8480 - val_accuracy: 0.7992\n",
      "Epoch 10/10\n",
      "884/884 [==============================] - 56s 63ms/step - loss: 0.3172 - accuracy: 0.9087 - val_loss: 0.8727 - val_accuracy: 0.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb9a868dfd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entreno la Red Neuronal. 10 epochs. 36 posibles caracteres como batch_size.\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=num_of_possible_characters, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el modelo\n",
    "\n",
    "model_file = \"captcha_model.hdf5\"\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save(model_file)\n",
    "\n",
    "print(\"Modelo guardado...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
